{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mine Twitter - NFL Search Patterns\n",
    "\n",
    "\n",
    "Ryan Timbrook (RTIMBROO)  \n",
    "DATE:11/30/2019 <br>\n",
    "Topic: Search Twitter for tweets on specific NFL Players, Coaches, and Teams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objective\n",
    "_____________________________________________________________________________________________\n",
    "Capture popular opinion of peoples tweets on certain NFL characters. \n",
    "Create a corpus of tweets for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________\n",
    "### Coding Environment Setup\n",
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for analysis and modeling\n",
    "import pandas as pd #data frame operations\n",
    "import numpy as np #arrays and math functions\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "from os import path\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for twitter\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# Twython packages for twitter\n",
    "from twython import Twython\n",
    "\n",
    "# packages for NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custome python packages\n",
    "import rtimbroo_utils as br             # custome python helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global properties\n",
    "notebook_file_name = 'search_twitter_nfl'\n",
    "report_file_name = 'search_twitter_nfl'\n",
    "app_name = 'search_twitter_nfl'\n",
    "log_level = 10 # 10-DEBUG, 20-INFO, 30-WARNING, 40-ERROR, 50-CRITICAL\n",
    "\n",
    "# setup working directory structure\n",
    "# set global properties\n",
    "dataDir = './data'\n",
    "outputDir = './output'\n",
    "configDir = './config'\n",
    "logOutDir = './logs'\n",
    "imageDir = './images'\n",
    "modelDir = './models'\n",
    "corpusDir = './corpus'\n",
    "# create base output directories if they don't exist\n",
    "if not os.path.exists(outputDir): os.mkdir(outputDir)\n",
    "if not os.path.exists(logOutDir): os.mkdir(logOutDir)\n",
    "if not os.path.exists(imageDir): os.mkdir(imageDir)\n",
    "if not os.path.exists(modelDir): os.mkdir(modelDir)\n",
    "if not os.path.exists(dataDir): os.mkdir(dataDir)\n",
    "if not os.path.exists(configDir): os.mkdir(configDir)\n",
    "if not os.path.exists(corpusDir): os.mkdir(corpusDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a logger for troubleshooting / data exploration\n",
    "logger = br.getFileLogger(logOutDir+'/',app_name,level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-01'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current date\n",
    "now = datetime.utcnow().isoformat()\n",
    "collection_date = re.findall('^[0-9]{4}-[0-9]{2}-[0-9]{2}',now)\n",
    "collection_date = collection_date[0]\n",
    "collection_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OBTAIN the data   \n",
    "________________________________________________________________________________________________\n",
    "Import external datasets for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Search API Limits:\n",
    "[Sandbox Package](https://developer.twitter.com/en/pricing/search-fullarchive)\n",
    "\n",
    "* Time frame:\tFull history\n",
    "* Tweets per request:\t100\n",
    "* Counts vs. data:\tData only\n",
    "* Query length:\t128 characters\n",
    "* Operator availability:\tStandard\n",
    "* Rate limit per minute:\t30 requests/min\n",
    "* Enrichments:\tn/a\n",
    "* Dev environments:\t1\t\n",
    "* Monthly Tweet cap:\t5k\t\n",
    "* Rate limit per second: 10 requests/sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Twitter API Object\n",
    "Using Twython 3.6 Twitter API Wrapper\n",
    "[Twython 3.6.0 reference documentation](https://twython.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter credentials\n",
    "with open(f'{configDir}/twitter_credentials.json', 'r') as f:\n",
    "    tw_cred = json.load(f)\n",
    "\n",
    "# setup client header arguments to pass along to the API\n",
    "client_args = {\n",
    "    'headers':{\n",
    "        'User-Agent': 'AI_Public_Sentiment_16860838'\n",
    "    },\n",
    "    'timeout':300,\n",
    "    \n",
    "}\n",
    "    \n",
    "# instantiate object\n",
    "py_tweets = Twython(tw_cred['CONSUMER_KEY'],\n",
    "                    tw_cred['CONSUMER_SECRET'],\n",
    "                    tw_cred['ACCESS_TOKEN'],\n",
    "                    tw_cred['ACCESS_SECRET'],\n",
    "                   client_args=client_args)\n",
    "\n",
    "logger.debug(f'{py_tweets.verify_credentials()}')\n",
    "logger.debug(f'{py_tweets.get_home_timeline()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set what to search on\n",
    "nfl_type = 'coach'\n",
    "search_on = 'bill_obrien'\n",
    "\n",
    "# setup base twitter search query\n",
    "search_terms=\"bill obrien\"+\" \"+\"houston texans\"\n",
    "\n",
    "# add filters to search criteria\n",
    "filtered_search_terms = search_terms + \" -filter:retweets\"\n",
    "\n",
    "#search_start_date = '2019-11-23' # limits to the last 7 days\n",
    "\n",
    "# number of tweets to return\n",
    "num_tweets = 100 # sandbox rate limit - 100 tweets per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search dates (from_date, to_date) - Saturday through Sunday\n",
    "search_date_ranges = [\n",
    "    ('2019-10-27','2019-11-3'),\n",
    "    ('2019-11-3','2019-11-10'),\n",
    "    ('2019-11-10','2019-11-17'),\n",
    "    ('2019-11-17','2019-11-24'),\n",
    "    ('2019-11-24','2019-12-1')\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_date(str_date):\n",
    "    import time\n",
    "    day_of_week = str_date.split(' ')[0]\n",
    "    month = str_date.split(' ')[1]\n",
    "    day_of_month = str_date.split(' ')[2]\n",
    "    year = str_date.split(' ')[-1]\n",
    "    time_of_day = str_date.split(' ')[3]\n",
    "\n",
    "\n",
    "    new_str_date = f'{month} {day_of_month}, {year}'\n",
    "    ts = time.strptime(new_str_date, '%b %d, %Y')\n",
    "    new_ds_str = f'{ts.tm_year}-{ts.tm_mon}-{ts.tm_mday}'\n",
    "\n",
    "    return new_ds_str, time_of_day\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Description: \n",
    "'''\n",
    "def config_query(search_term,since=None,until=None,count=100,lang='en',result_type='mixed'):\n",
    "    \n",
    "    # query\n",
    "    search = {\n",
    "        'q':search_term,\n",
    "        'since':since,              # from_date\n",
    "        'until':until,              # Date format YYYY-MM-DD - returns tweets created before the given date\n",
    "        'lang':lang,\n",
    "        'result_type':result_type,    # mixed, recent, popular\n",
    "        'count':count,                # max is 100, defult is 15 per page\n",
    "\n",
    "        #'since_id': ,              # returns results with an ID more recent than the specified ID - if the limit of Tweets has occured since the since_id, the since_id will be forced to the oldest ID available\n",
    "        #'max_id': ,                # returns results with an ID older than or equal to the specified ID\n",
    "    }\n",
    "    \n",
    "    logger.debug(f'config_query: search:\\n{search}')\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function Description: \n",
    "'''\n",
    "def page_search(twitter,query,text_file,raw_file):\n",
    "    results = twitter.cursor(twitter.search,**query, return_pages=True)\n",
    "    # search tweets\n",
    "    tweets_dict = {'id':[],'created_at':[],'date':[],'time':[],'user':[],'text':[],'favorite_count':[]}\n",
    "    page_cnt = 0\n",
    "    result_cnt = 0\n",
    "    with io.open(f'{text_file}', 'a',encoding='utf8') as f:\n",
    "        with io.open(f'{raw_file}','a',encoding='utf8') as r:\n",
    "            try: \n",
    "                # page is a list of twitter results\n",
    "                for i, page in enumerate(results):\n",
    "                    page_cnt +=1\n",
    "                    logger.info(f'Page: [{i}]')\n",
    "                    try:\n",
    "                        for j,result in enumerate(page):\n",
    "                            #logger.info(f'result type:{type(result)}')\n",
    "                            #break\n",
    "                            \n",
    "                            result_cnt += 1\n",
    "                            logger.info(f'Result: [{j}]')\n",
    "                            try:\n",
    "                                logger.debug(f'{result[\"id_str\"]} | {result[\"user\"][\"screen_name\"]} | {result[\"created_at\"]} | {result[\"text\"]} | {result[\"user\"][\"favourites_count\"]}')\n",
    "\n",
    "                                # dump raw tweet to file as json\n",
    "                                #raw_tweet = json.load(result)\n",
    "                                dump = json.dumps(result)\n",
    "                                r.write(dump)\n",
    "                                r.write('\\n')\n",
    "                                \n",
    "                                # dump tweet text to file\n",
    "                                f.write(f'{result[\"id_str\"]} {result[\"text\"]}')\n",
    "                                f.write('\\n')\n",
    "                                \n",
    "                                # add key attributes to tweets dictionary as return results\n",
    "                                tweets_dict['id'].append(result[\"id_str\"])\n",
    "                                tweets_dict['created_at'].append(result[\"created_at\"])\n",
    "                                tweets_dict['date'].append(convert_str_date(result[\"created_at\"])[0])\n",
    "                                tweets_dict['time'].append(convert_str_date(result[\"created_at\"])[1])        \n",
    "                                tweets_dict['user'].append(result[\"user\"][\"screen_name\"])\n",
    "                                tweets_dict['text'].append(result[\"text\"])\n",
    "                                tweets_dict['favorite_count'].append(result[\"user\"][\"favourites_count\"])\n",
    "                                       \n",
    "                                #break\n",
    "\n",
    "                            except BaseException as be:\n",
    "                                logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "                                             \n",
    "                    except BaseException as be:\n",
    "                        logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "                    #break\n",
    "            except BaseException as be:\n",
    "                logger.warning(f'**WARNING** Caught BaseException: {be}')\n",
    "    \n",
    "    logger.info(f'page_search: processed page_cnt:[{page_cnt}] | total result_cnt: [{result_cnt}]')\n",
    "    \n",
    "    return pd.DataFrame.from_dict(tweets_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Twitter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Twython 3.6.0 reference documentation](https://twython.readthedocs.io/en/latest/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_range: 2019-10-27_2019-11-3\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-3_2019-11-10\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-10_2019-11-17\n",
      "Page: [0]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[1] | total result_cnt: [0]\n",
      "search_range: 2019-11-17_2019-11-24\n",
      "Page: [0]\n",
      "Result: [0]\n",
      "Page: [1]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[2] | total result_cnt: [1]\n",
      "search_range: 2019-11-24_2019-12-1\n",
      "Page: [0]\n",
      "Result: [0]\n",
      "Result: [1]\n",
      "Result: [2]\n",
      "Result: [3]\n",
      "Result: [4]\n",
      "Result: [5]\n",
      "Result: [6]\n",
      "Result: [7]\n",
      "Result: [8]\n",
      "Result: [9]\n",
      "Result: [10]\n",
      "Result: [11]\n",
      "Result: [12]\n",
      "Result: [13]\n",
      "Result: [14]\n",
      "Result: [15]\n",
      "Result: [16]\n",
      "Result: [17]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f3c8' in position 110: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-18c4501fe078>\", line 25, in <module>\n",
      "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename)\n",
      "  File \"<ipython-input-12-d70291183362>\", line 25, in page_search\n",
      "    logger.debug(f'{result[\"id_str\"]} | {result[\"user\"][\"screen_name\"]} | {result[\"created_at\"]} | {result[\"text\"]} | {result[\"user\"][\"favourites_count\"]}')\n",
      "Message: \"1199717299894145024 | SportsbookBTC | Wed Nov 27 15:51:08 +0000 2019 | NFL  🏈 As always, Patriots stand in the way for Bill O'Brien and Texans https://t.co/BeeY9aPaR3 ►… https://t.co/wfEpc43JPK | 85\"\n",
      "Arguments: ()\n",
      "Result: [18]\n",
      "Result: [19]\n",
      "Result: [20]\n",
      "Result: [21]\n",
      "Result: [22]\n",
      "Result: [23]\n",
      "Result: [24]\n",
      "Page: [1]\n",
      "**WARNING** Caught BaseException: generator raised StopIteration\n",
      "page_search: processed page_cnt:[2] | total result_cnt: [25]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\logging\\__init__.py\", line 1037, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f3c8' in position 3564: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\rt310\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-18c4501fe078>\", line 27, in <module>\n",
      "    logger.debug(f'search result df: \\n{result_df}')\n",
      "Message: 'search result df: \\n                     id                      created_at        date      time  \\\\\\n0   1200324875115810816  Fri Nov 29 08:05:25 +0000 2019  2019-11-29  08:05:25   \\n1   1200086820928622592  Thu Nov 28 16:19:29 +0000 2019  2019-11-28  16:19:29   \\n2   1200023580542676993  Thu Nov 28 12:08:11 +0000 2019  2019-11-28  12:08:11   \\n3   1199968219286687745  Thu Nov 28 08:28:12 +0000 2019  2019-11-28  08:28:12   \\n4   1199961952556109824  Thu Nov 28 08:03:18 +0000 2019  2019-11-28  08:03:18   \\n5   1199961736335560706  Thu Nov 28 08:02:26 +0000 2019  2019-11-28  08:02:26   \\n6   1199838956545699840  Wed Nov 27 23:54:33 +0000 2019  2019-11-27  23:54:33   \\n7   1199829879304441857  Wed Nov 27 23:18:29 +0000 2019  2019-11-27  23:18:29   \\n8   1199726628529692672  Wed Nov 27 16:28:12 +0000 2019  2019-11-27  16:28:12   \\n9   1199726602415792128  Wed Nov 27 16:28:06 +0000 2019  2019-11-27  16:28:06   \\n10  1199724456844742657  Wed Nov 27 16:19:34 +0000 2019  2019-11-27  16:19:34   \\n11  1199722853186375680  Wed Nov 27 16:13:12 +0000 2019  2019-11-27  16:13:12   \\n12  1199719952682491905  Wed Nov 27 16:01:41 +0000 2019  2019-11-27  16:01:41   \\n13  1199719769848590337  Wed Nov 27 16:00:57 +0000 2019  2019-11-27  16:00:57   \\n14  1199719141764214786  Wed Nov 27 15:58:27 +0000 2019  2019-11-27  15:58:27   \\n15  1199718596601155584  Wed Nov 27 15:56:17 +0000 2019  2019-11-27  15:56:17   \\n16  1199718310289584133  Wed Nov 27 15:55:09 +0000 2019  2019-11-27  15:55:09   \\n17  1199717299894145024  Wed Nov 27 15:51:08 +0000 2019  2019-11-27  15:51:08   \\n18  1199717275651100673  Wed Nov 27 15:51:02 +0000 2019  2019-11-27  15:51:02   \\n19  1199709563181785088  Wed Nov 27 15:20:24 +0000 2019  2019-11-27  15:20:24   \\n20  1199653099989803008  Wed Nov 27 11:36:02 +0000 2019  2019-11-27  11:36:02   \\n21  1199646811356426240  Wed Nov 27 11:11:02 +0000 2019  2019-11-27  11:11:02   \\n22  1199357598572646400  Tue Nov 26 16:01:49 +0000 2019  2019-11-26  16:01:49   \\n23  1198669122814578689  Sun Nov 24 18:26:03 +0000 2019  2019-11-24  18:26:03   \\n24  1198669045849034757  Sun Nov 24 18:25:45 +0000 2019  2019-11-24  18:25:45   \\n\\n               user                                               text  \\\\\\n0           TimP103  Bill O\\'Brien is the most successful ex-Bill Be...   \\n1      STERLING9798  As always, Patriots stand in the way for Bill ...   \\n2      monkey_viral  #As always, Patriots stand in the way for Bill...   \\n3             SVOFL  As always, Patriots stand in the way for Bill ...   \\n4            100UBF  As always, Patriots stand in the way for Bill ...   \\n5      Sportsgriduk  As always, Patriots stand in the way for Bill ...   \\n6       sport_wolrd  As always, Patriots stand in the way for Bill ...   \\n7       PhenomDaOne  As always, Patriots stand in the way for Bill ...   \\n8     FantasyJabber  As always, Patriots stand in the way for Bill ...   \\n9     profbinsights  As always, Patriots stand in the way for Bill ...   \\n10       RonBohning  As always, Patriots stand in the way for Bill ...   \\n11   WinEasy_quotes  As always, Patriots stand in the way for Bill ...   \\n12        max_twest  Football news! As always, Patriots stand in th...   \\n13    SwaggyDoo_101  As always, Patriots stand in the way for Bill ...   \\n14  AllTheFootballs  As always, Patriots stand in the way for Bill ...   \\n15      nickschreck  Via ESPN - #ESPN #NFL #FantasyFootball \"As alw...   \\n16       LetsTalkFF  \"As always, Patriots stand in the way for Bill...   \\n17    SportsbookBTC  NFL  🏈 As always, Patriots stand in the way fo...   \\n18    Sportnewsbuzz  As always, Patriots stand in the way for Bill ...   \\n19       Texans_TT1  As always, Patriots stand in the way for Bill ...   \\n20    PatsFans_News  ESPN Boston: As always, Patriots stand in the ...   \\n21       ESPNBoston  As always, Patriots stand in the way for Bill ...   \\n22   spacecity4life  @NFLonFOX @HoustonTexans @JayGlazer yall must ...   \\n23         brkp1999  THREE REASONS: Bill O’Brien has been hurting t...   \\n24   HouseOfHouston  THREE REASONS: Bill O’Brien has been hurting t...   \\n\\n    favorite_count  \\n0               11  \\n1              360  \\n2              569  \\n3               34  \\n4                7  \\n5              130  \\n6                0  \\n7              341  \\n8               53  \\n9               45  \\n10             128  \\n11              49  \\n12              15  \\n13           28323  \\n14             101  \\n15           40549  \\n16           10124  \\n17              85  \\n18             715  \\n19               0  \\n20             104  \\n21             143  \\n22            1591  \\n23            1734  \\n24           15124  '\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Execute Twitter search by pre-configured date ranges\n",
    "'''\n",
    "search_range_results_df = pd.DataFrame()\n",
    "# execute search by date ranges\n",
    "for dates in search_date_ranges:\n",
    "    search_range = f'{dates[0]}_{dates[1]}'\n",
    "    logger.info(f'search_range: {search_range}')\n",
    "    \n",
    "    # output file names based on date range search\n",
    "    outputPath = f'{dataDir}/{nfl_type}/{search_on}/{search_range}'\n",
    "    if not os.path.exists(outputPath): os.makedirs(outputPath)\n",
    "        \n",
    "    tweet_filename=f'{outputPath}/tweet_text.txt'\n",
    "    raw_filename=f'{outputPath}/tweet_raw.txt'\n",
    "        \n",
    "    if not os.path.exists(f'{tweet_filename}'): open(f'{tweet_filename}', 'a').close()\n",
    "    if not os.path.exists(f'{raw_filename}'): open(f'{raw_filename}', 'a').close()\n",
    "    \n",
    "    \n",
    "    # configure query by dates\n",
    "    query = config_query(filtered_search_terms,since=dates[0],until=dates[1],count=100)\n",
    "    #break\n",
    "    \n",
    "    result_df = page_search(py_tweets,query,tweet_filename,raw_filename) \n",
    "    \n",
    "    logger.debug(f'search result df: \\n{result_df}')\n",
    "    # merge dataframes\n",
    "    search_range_results_df = search_range_results_df.append(result_df, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198337897507803142</td>\n",
       "      <td>Sat Nov 23 20:29:53 +0000 2019</td>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>20:29:53</td>\n",
       "      <td>pfrumors</td>\n",
       "      <td>The All-Pro safety was briefly connected to th...</td>\n",
       "      <td>3561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200324875115810816</td>\n",
       "      <td>Fri Nov 29 08:05:25 +0000 2019</td>\n",
       "      <td>2019-11-29</td>\n",
       "      <td>08:05:25</td>\n",
       "      <td>TimP103</td>\n",
       "      <td>Bill O'Brien is the most successful ex-Bill Be...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200086820928622592</td>\n",
       "      <td>Thu Nov 28 16:19:29 +0000 2019</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>16:19:29</td>\n",
       "      <td>STERLING9798</td>\n",
       "      <td>As always, Patriots stand in the way for Bill ...</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200023580542676993</td>\n",
       "      <td>Thu Nov 28 12:08:11 +0000 2019</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>12:08:11</td>\n",
       "      <td>monkey_viral</td>\n",
       "      <td>#As always, Patriots stand in the way for Bill...</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199968219286687745</td>\n",
       "      <td>Thu Nov 28 08:28:12 +0000 2019</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>08:28:12</td>\n",
       "      <td>SVOFL</td>\n",
       "      <td>As always, Patriots stand in the way for Bill ...</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                      created_at        date      time  \\\n",
       "0  1198337897507803142  Sat Nov 23 20:29:53 +0000 2019  2019-11-23  20:29:53   \n",
       "1  1200324875115810816  Fri Nov 29 08:05:25 +0000 2019  2019-11-29  08:05:25   \n",
       "2  1200086820928622592  Thu Nov 28 16:19:29 +0000 2019  2019-11-28  16:19:29   \n",
       "3  1200023580542676993  Thu Nov 28 12:08:11 +0000 2019  2019-11-28  12:08:11   \n",
       "4  1199968219286687745  Thu Nov 28 08:28:12 +0000 2019  2019-11-28  08:28:12   \n",
       "\n",
       "           user                                               text  \\\n",
       "0      pfrumors  The All-Pro safety was briefly connected to th...   \n",
       "1       TimP103  Bill O'Brien is the most successful ex-Bill Be...   \n",
       "2  STERLING9798  As always, Patriots stand in the way for Bill ...   \n",
       "3  monkey_viral  #As always, Patriots stand in the way for Bill...   \n",
       "4         SVOFL  As always, Patriots stand in the way for Bill ...   \n",
       "\n",
       "   favorite_count  \n",
       "0          3561.0  \n",
       "1            11.0  \n",
       "2           360.0  \n",
       "3           569.0  \n",
       "4            34.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_range_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_range_results_df shape: (26, 7)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'search_range_results_df shape: {search_range_results_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_tweets.get_lastfunction_header('x-rate-limit-remaining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_tweets.get_home_timeline()\n",
    "py_tweets.get_lastfunction_header('x-rate-limit-remaining')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Full DataFrame of search results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = f'{dataDir}/{nfl_type}/{search_on}'\n",
    "search_range_results_df.to_csv(f'{outputPath}/search-result_twitter_text_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
